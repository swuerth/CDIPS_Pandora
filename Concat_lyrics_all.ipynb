{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/py2/lib/python2.7/site-packages/fuzzywuzzy/fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "# Import everything we'll need in this notebook here\n",
    "import billboard\n",
    "from billboard import ChartData\n",
    "import pdb \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# for lyrics stuff (mxm)\n",
    "from musixmatch.track import TracksCollection\n",
    "from musixmatch.lyrics import Lyrics\n",
    "\n",
    "# for fuzzy matching artist names (when matching hot100 song to lyrics in mxm)\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# for joining list of strings\n",
    "import string\n",
    "\n",
    "\n",
    "# for ascii / utf8 errors, run this\n",
    "import sys\n",
    "default_stdout = sys.stdout\n",
    "default_stderr = sys.stderr\n",
    "reload(sys)\n",
    "sys.stdout = default_stdout\n",
    "sys.stderr = default_stderr\n",
    "print 'testing!'\n",
    "\n",
    "import glob\n",
    "\n",
    "import datetime\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_files =  6\n",
      "['/Users/minerva/Desktop/GitHub/CDIPS_Pandora/MXM_Top_20_Monthly_ByDecade/Lyrics_1950-01-01-1960-01-01MaxRank20', '/Users/minerva/Desktop/GitHub/CDIPS_Pandora/MXM_Top_20_Monthly_ByDecade/Lyrics_1960-01-01-1970-01-01MaxRank20', '/Users/minerva/Desktop/GitHub/CDIPS_Pandora/MXM_Top_20_Monthly_ByDecade/Lyrics_1970-01-01-1980-01-01MaxRank20', '/Users/minerva/Desktop/GitHub/CDIPS_Pandora/MXM_Top_20_Monthly_ByDecade/Lyrics_1980-01-01-1990-01-01MaxRank20', '/Users/minerva/Desktop/GitHub/CDIPS_Pandora/MXM_Top_20_Monthly_ByDecade/Lyrics_1990-01-01-2000-01-01MaxRank20', '/Users/minerva/Desktop/GitHub/CDIPS_Pandora/MXM_Top_20_Monthly_ByDecade/Lyrics_2000-01-01-2015-01-01MaxRank20']\n"
     ]
    }
   ],
   "source": [
    "dir_name = \"/Users/minerva/Desktop/GitHub/CDIPS_Pandora/MXM_Top_20_Monthly_ByDecade\"\n",
    "dir_name2 = \"/Users/minerva/Desktop/GitHub/CDIPS_Pandora/\"\n",
    "\n",
    "y1=1950\n",
    "y2=2015\n",
    "\n",
    "file_list = glob.glob(dir_name + \"/Lyrics*\") #or wherever your csvs are stored\n",
    "print 'num_files = ', len(file_list)\n",
    "num_files = len(file_list)\n",
    "print file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 has  264  songs\n",
      "df2 has  264  songs\n",
      "joined df has 528\n",
      "df1 has  528  songs\n",
      "df2 has  1756  songs\n",
      "joined df has 2284\n",
      "df1 has  2284  songs\n",
      "df2 has  1411  songs\n",
      "joined df has 3695\n",
      "df1 has  3695  songs\n",
      "df2 has  1577  songs\n",
      "joined df has 5272\n",
      "df1 has  5272  songs\n",
      "df2 has  1183  songs\n",
      "joined df has 6455\n",
      "df1 has  6455  songs\n",
      "df2 has  1628  songs\n",
      "joined df has 8083\n"
     ]
    }
   ],
   "source": [
    "#read df from pickle file\n",
    "\n",
    "i=0\n",
    "df_joined = pd.read_pickle(file_list[i])\n",
    "df_joined.head()\n",
    "\n",
    "for y in xrange(0,num_files):\n",
    "    df1 = df_joined\n",
    "    df1.head()\n",
    "    df2 = pd.read_pickle(file_list[i]) \n",
    "    df2.head()\n",
    "    \n",
    "    #\n",
    "    # testing how to join the databases from each year. \n",
    "    # we'll want to maybe remove duplicate entries in the future, but one stupid way is to just \"append\n",
    "    print 'df1 has ', len(df1), ' songs'\n",
    "    print 'df2 has ', len(df2), ' songs'\n",
    "    df_joined = df1.append(df2)\n",
    "    print 'joined df has', len(df_joined)\n",
    "    \n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will save df as :  /Users/minerva/Desktop/GitHub/CDIPS_Pandora//Lyrics_1950-01-01-2015-01-01MaxRank20\n"
     ]
    }
   ],
   "source": [
    "# it may make sense to set the index as lyrics id:\n",
    "df_joined.set_index('lyrics_id')\n",
    "\n",
    "max_rank=20\n",
    "start_date = datetime.date(year=y1,month=1,day=1)\n",
    "end_date = datetime.date(year=y2,month=1,day=1)\n",
    "\n",
    "name2save = dir_name2 + \"/Lyrics_\" + str(start_date)+'-'+str(end_date)+'MaxRank'+str(max_rank)\n",
    "print 'will save df as : ', name2save\n",
    "\n",
    "df_joined.to_pickle(name2save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join them all!\n",
    "# make a loop!\n",
    "# you can do it!\n",
    "# YES WE CAN!!!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py2]",
   "language": "python",
   "name": "Python [py2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
